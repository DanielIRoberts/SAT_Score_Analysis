---
title: "Expenditures and Test Scores"
author: "Daniel Roberts dir170130"
date: "5/7/2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{R Setup, include = 1}
# Caching
knitr::opts_chunk$set(cache = 1, echo = 1)

# Contains data set
library(faraway)

# Used for graphing and visuals
library(ggplot2)
library(reshape2)

# Used for analyis
library(MASS)
library(car)
library(MASS)
library(leaps)
```

## The Data

The data set 'sat' from the 'faraway' package consists of three potential 
response variables, four potential regressor variables and 50 observations. In 
this analysis the focus will be on predicting the total SAT score so the score
breakdown is removed from the data set for easier use of the data set. The 
variables can be broken down as follows:

SAT Scores Response and regressor variables
---------- --------------------------------
y          Total Score
x1         Expenditure per Student ($1000)
x2         Students/Teacher
x3         Teacher Salary ($1000)
x4         Percent of Test Takers

This data was gathered as averages from each state from the 1994 - 1995 school 
year, so each data point is a state average which is why there are 50. We can 
fit the full data model with the following:

```{R Intitial Data}
# Loading data
data <- sat

# Renaming variables
y <- data$total

x1 <- data$expend
x2 <- data$ratio
x3 <- data$salary
x4 <- data$takers

# Fitting the full model
full <- lm(y ~ x1 + x2 + x3 + x4)
```

\newpage

```{R Sum Full}
summary(full)
```

## Analysis of the Full Model
### Checking for Multicollinearity  

Even though mulicollinearity does not occur often, it is important to check
the model's VIF values to ensure that it is not effected by the issue.  

```{R Full VIF}
vif(full)
```  

As seen in the summary since all VIF values are less than 10, even though 
expenditures and salary are close, we can say that there is no issues with
multicollinearity in the full model.  

### Regression on Full Model

The analysis process starts with full model residual analysis to get a "big 
picture" idea of the data, regressors, and any potential outliers. This process
can begin by looking at the histogram of studentized residuals and QQ-Plot of 
the studentized residuals.  

```{R Full StudRes Hist and QQ, fig.width = 8, fig.height = 5, echo = 1}
par(mfrow = c(1,2))
hist(studres(full), breaks = 10, freq = F, col = "lightblue")
qqPlot(full)
```

We can see that the studentized residuals are normalized decently, but in the 
QQ-Plot analysis we see that points 44 and 48 made need further
inspection.  

Next we further inspect the data by looking at the individual standardized and
studentized residuals via barplots.  

```{R Full Bars, fig.height = 3.75}
# Standardized
barplot(height = stdres(full), names.arg = 1:50, main = "Studentized Residuals", 
        xlab = "Index", ylab = "Standardized Resid", ylim = c(-3, 3)) +
  abline(h = 2, col = "Red", lwd = 3) + abline(h = -2, col = "Red", lwd = 3)
which(stdres(full) > 2 | stdres(full) < -2)

# Studentized
barplot(height = studres(full), names.arg = 1:50, main = "Studentized Residuals", 
        xlab = "Index", ylab = "Studentized Resid", ylim = c(-3.5, 3.5)) +
  abline(h = 2, col = "Red", lwd = 3) +abline(h = -2, col = "Red", lwd = 3)
which(studres(full) > 2 | studres(full) < -2)
```  

Based on the standardized and studentized residuals, points 44 and 48 are
once again seen to be a potenial distortion of the model, but 29 and
34 may also require further inspection now.  

We can continue the analysis via a look into the measures of influence by the 
points.  

```{R Full Influence}
# Measures of influence summary
fullInf <- influence.measures(full)
summary(fullInf)

# Plotted
influenceIndexPlot(full, vars = c("Cook", "Hat"))

# DFBETAS analysis
dfbetasPlots(full, intercept = 1)

c(5, 30, 32, 44, 48)
```  

From these measures of influence we see that points 44 and 48 continue to
be an issue and may need to be removed. Aside from those two observations the 
rest have not been of trouble.  

We conduct a final test of studentized residuals vs fitted values to conclude 
the residual testing.  

```{R Full Stud vs Fitted}
residualPlot(full, type = "rstudent", quadratic = F, col = "dodgerblue", 
             pch = 16)
```

Analyzing this final plot we see that aside from point 48 the graph is 
fairly evenly spread.  

### Results of Initial Analysis  

After initial analysis of the full model using all data we can conclude that the 
data does not need to be transformed but points 44 and 48 should be 
removed and the data should then be reanalyzed as a full model before moving 
onto model selection.  

\newpage

## Residual Analysis with Modified Data  

Since the full model has been anaylyzed once already we will take a look at all 
plots together rather than going step-by-step. We start by modifying our data.

```{R Modding Data}
# Resetting and removing
data <- sat[-c(48, 44), -c(5, 6)]
n <- length(data$total)

# Renaming and fitting
y <- data$total

x1 <- data$expend
x2 <- data$ratio
x3 <- data$salary
x4 <- data$takers

full <- lm(y ~ x1 + x2 + x3 + x4)

# Summary
summary(full)

# Checking vif
vif(full)
```  

### Modified Data Residual Analysis
We see that there is still no issues with multicollinearity so we move onto 
residual analysis.  

```{R Full Modded Residual Analysis, fig.height = 3.75}
# Standardized
barplot(height = stdres(full), names.arg = 1:48, main = "Studentized Residuals", 
        xlab = "Index", ylab = "Standardized Resid", ylim = c(-3, 3)) +
  abline(h = 2, col = "Red", lwd = 3) + abline(h = -2, col = "Red", lwd = 3)
which(stdres(full) > 2 | stdres(full) < -2)

# Studentized
barplot(height = studres(full), names.arg = 1:48, main = "Studentized Residuals", 
        xlab = "Index", ylab = "Studentized Resid", ylim = c(-3, 3)) +
  abline(h = 2, col = "Red", lwd = 3) +abline(h = -2, col = "Red", lwd = 3)
which(studres(full) > 2 | studres(full) < -2)

# Measures of influence summary
fullInf <- influence.measures(full)
summary(fullInf)
```  

\newpage

```{R Full Modded Cont}
# Plotted
influenceIndexPlot(full, vars = c("Cook", "Hat"))

# DFBETAS analysis
dfbetasPlots(full, intercept = 1)
```  

We can already see from the barplots of the standardized and studentized 
residuals that there is improvement after removing points 44 and 48. 

```{R Final Full Modded Res, fig.width = 8, fig.height = 5}
par(mfrow = c(1,2))
hist(studres(full), breaks = 10, freq = F, col = "lightblue")
qqPlot(full)

par(mfrow = c(1,1))
residualPlot(full, type = "rstudent", quadratic = F, col = "dodgerblue", 
             pch = 16)
```  

### Results of Modified Data Analysis
After observing the histogram and QQ-Plot we see that the data has become slightly 
less normalized but not by enough to be concerning and the studentized residuals 
vs fitted values plot is evenly dispersed. Based on this result, the other 
residual analysis graphs and improvment in the adjusted $R^2$ value we can 
conclude that the model is helped by the removal and can move on to model fitting.

\newpage

## Model Fitting  

Now that we have our final dataset we must see which combination of variables 
provides the best possible model. We do this by adding or removing variables 
from the model one at a time based on specific selection criteria. For this data 
we use a forward selection method.  

### Forward Selection  

```{R Forward Selection}
fwd <- regsubsets(total ~ ., method = "forward", data = data)
summary(fwd)
```  

From this forward selection process we see that all regressors are candidates to 
be in the final model, so we now have to generate additional selection criteria 
and use this to determine the best possible model.  

### Selction Criteria  

```{R Selection Criteria}
mse <- summary(fwd)$rss / (n - (2:5))
adjr2 <- summary(fwd)$adjr2
cp <- summary(fwd)$cp
bic <- summary(fwd)$bic
crit <- cbind(mse, adjr2, cp, bic)
colnames(crit) <- c("MSE", "Adj R2", "Cp", "BIC")
rownames(crit) <- 2:5
crit
```  

From this table we can already see that the full four variable model may be the 
best option, but the data becomes much more visible when applied to a graph.  

### Graphing Selection Criteria

```{R Graphing Crit}
par(mfrow=c(1,2))
plot(2:5, mse, col = "blue", type = "l", xlab = "p", ylab = "MSE")
plot(2:5, adjr2, col = "blue", type = "l", xlab = "p", ylab = "Adj R2")
```  

We do not graph the $R^2$ value here but rather the adjusted $R^2$ value becuase 
the $R^2$ increases with number of variables. This means it favors models with 
more variables and is not a good indicator for model selection. We continue by 
looking at the $C_p$ and BIC values.  

```{R CP BIC Graphing}
par(mfrow=c(1,2))
plot(2:5, cp, col = "blue", xlab = "p", ylab = "Cp", pch=16, cex=1) +
  abline(a = 0,b = 1, col = "red")
plot(2:5, bic, col = "blue", type = "l", xlab = "p", ylab = "BIC")
```  

We see from the $C_p$ graph that the idea of choosing the full model as the 
final model continues to be a good descision, however it could also indicate 
that the three variable model is an option. We also see that the BIC graph 
indicates a three variable model, however this may be due to the fact that the 
data set being used has a relativley small number of observations which 
negatively effects the accuracy of the BIC values.  

There is a final test to perform to confirm which model may be the best option 
for this data set, the stepwise selection method.

### Stepwise Selection  

```{R Step AIC}
intercept <- lm(total ~ 1, data = data)
aic <- stepAIC(intercept, direction = "forward", scope = list(lower = intercept, 
              upper = ~ x1 + x2 + x3 + x4))
```  

From this stepwise selection we see that the three variable model may be just 
as good of an option as the full model, however the final AIC values that 
determines the three variable vs full model only have a difference of .34 so 
either model could be argued as best by this method. Due to the fact that the 
last test was partially inconclusive we can perform a backwards selection as an
additional test.  

### Backward Selection  

```{R Backwards}
bwd <- regsubsets(total ~ ., method = "backward", data = data)
summary(bwd)

# Selection criteria
mse <- summary(bwd)$rss / (n - (2:5))
adjr2 <- summary(bwd)$adjr2
cp <- summary(bwd)$cp
bic <- summary(bwd)$bic
crit <- cbind(mse, adjr2, cp, bic)
colnames(crit) <- c("MSE", "Adj R2", "Cp", "BIC")
rownames(crit) <- 2:5
crit
```  

From both the model selection and most of the selection criteria we see that a 
full model is the best model for this data. The only contradictory evidence is 
BIC values which as stated earlier can be less accurate with less observations 
like in our case.  

### Model Fitting Results  

After perfroming intensive model fitting tests we have determined that a full 
model with all four regressors is the best option for regression. Now that we 
have determined that a full model is the best option and since we have already 
run residual testing on the model we can take a look at the regressors plotted 
individually against the predicted SAT score values and then make 
recomendations.  

## Regressors vs Predicted Values  

```{R Final Model Plotting}
data2 <- melt(data, id.vars = 'total')
ggplot(data2) + geom_jitter(aes(value, total, colour = variable)) + 
  geom_smooth(aes(value, total, colour = variable), method = lm, se = FALSE) + 
  facet_wrap(~ variable, scales = "free_x")
```  

## Conclusion  

From this regression model we can see that surprisingly that the more money 
spent per student and the higher a teacher's salary, the worse a student 
performs on the SAT overall. This may be due to a percieved laziness in more 
weathly areas such as suburbs, whereas students in lower income areas, and 
therefore less money to schools, are more driven to succeed to leave the area 
they are in.  

Not as surprisingly we see that the higher the percentage of test takers in that 
are in a state the worse the states overall average is. This point is less 
interesting because it comes mostly as common sense that the more people who 
take an exam the worse the overall average will be.  

Finally we see that the student to teacher ratio does not have a strong effect 
on the total SAT score. This comes as more of a surprise since you would think 
more one on one time with a teacher would improve overall retention of a 
taught subject.  

## Reflection on Analysis

Looking back on the overall anaylsis of the data set, having more data over 
several school years would improve the overall accuracy of the regression. If 
data over multiple years was not available the data broken down by county or 
city averages rather than by state could also be a good way to add additional 
data while still being obtainable.  

Having more variables to analyze could potentially help the overall regression 
depending on what variables could be available for analysis. While a subject 
matter expert would be the best one to determine additional variables I believe 
that having the average student GPA would also be useful as it is a good 
determination of a student's knowledge.  

I believe the regression might have been skewed by the fact that most of the 
data exists on the lower end of the regressor variable's range. This is 
primarily seen in expenditures and teacher salary as in both catagories the 
majority of data points are in the bottom 50% of the the value range. Seeing the 
data from higher end neighborhoods or private schools could provide more data 
on the higher end of the value range.  

\newpage